{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ad2326f-5453-4c6c-98bb-3239570d90b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n"
     ]
    }
   ],
   "source": [
    "from NeuroEvolution.datasets.load import * \n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(\"imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e227eb5-14be-420f-b773-bcbbd86d0544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(dataset):\n",
    "    all_images = torch.stack([torch.tensor(element[\"img\"], dtype=torch.float32) for element in dataset[\"train\"]]) \n",
    "    # i already normalized b4 for the doodles\n",
    "    #all_images /= 255.0 \n",
    "    \n",
    "    \n",
    "    return all_images.mean(), all_images.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "347b8274-19f4-4059-891f-bce9f5cf7bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "doodle_two_class = load_doodle_two_classes()\n",
    "doodle_five_class = load_doodle()\n",
    "cifar_10 = load_cifar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14bccc49-2ed9-4a65-aab6-1dce6dbfafd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Doodle Two Classes\n",
      "mean: 0.20931898057460785 || std: 0.3547174036502838\n"
     ]
    }
   ],
   "source": [
    "# google doodle two_classes\n",
    "google_doodle_two = normalize(doodle_two_class)\n",
    "print(\"Google Doodle Two Classes\")\n",
    "print(f\"mean: {google_doodle_two[0]} || std: {google_doodle_two[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45f466f1-3f9a-43c6-bc7c-727bd2be8208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Doodle Five Classes\n",
      "mean: 0.17667199671268463 || std: 0.3353184163570404\n"
     ]
    }
   ],
   "source": [
    "google_doodle = normalize(doodle_five_class)\n",
    "print(\"Google Doodle Five Classes\")\n",
    "print(f\"mean: {google_doodle[0]} || std: {google_doodle[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "413d7d18-756f-46eb-b530-dac937fc5111",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be real number, not PngImageFile",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m cifar = \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcifar_10\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCifar10\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcifar[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m || std: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcifar[\u001b[32m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mnormalize\u001b[39m\u001b[34m(dataset)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnormalize\u001b[39m(dataset):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     all_images = torch.stack([\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m dataset[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m]]) \n\u001b[32m      3\u001b[39m     all_images /= \u001b[32m255.0\u001b[39m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m all_images.mean(), all_images.std()\n",
      "\u001b[31mTypeError\u001b[39m: must be real number, not PngImageFile"
     ]
    }
   ],
   "source": [
    "# gotta fix this... \n",
    "cifar = normalize(cifar_10)\n",
    "print(\"Cifar10\")\n",
    "print(f\"mean: {cifar[0]} || std: {cifar[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
